{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC7n-w2zBaI-",
        "outputId": "bcce0092-fe17-40df-c44b-1ea4d10e85af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting realtabformer\n",
            "  Using cached realtabformer-0.2.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets>=2.6.1 (from realtabformer)\n",
            "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.21.6 in ./newprojectenv/lib/python3.12/site-packages (from realtabformer) (2.2.3)\n",
            "Requirement already satisfied: pandas>=1.3.5 in ./newprojectenv/lib/python3.12/site-packages (from realtabformer) (2.2.3)\n",
            "Collecting scikit-learn>=1.0.2 (from realtabformer)\n",
            "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
            "Collecting shapely>=1.8.5.post1 (from realtabformer)\n",
            "  Using cached shapely-2.0.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting tqdm>=4.64.1 (from realtabformer)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting transformers>=4.46.0 (from transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: filelock in ./newprojectenv/lib/python3.12/site-packages (from datasets>=2.6.1->realtabformer) (3.17.0)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.6.1->realtabformer)\n",
            "  Downloading pyarrow-19.0.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.6.1->realtabformer)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./newprojectenv/lib/python3.12/site-packages (from datasets>=2.6.1->realtabformer) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.6.1->realtabformer)\n",
            "  Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.6.1->realtabformer)\n",
            "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.6.1->realtabformer)\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets>=2.6.1->realtabformer)\n",
            "  Using cached aiohttp-3.11.13-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets>=2.6.1->realtabformer)\n",
            "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in ./newprojectenv/lib/python3.12/site-packages (from datasets>=2.6.1->realtabformer) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./newprojectenv/lib/python3.12/site-packages (from datasets>=2.6.1->realtabformer) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./newprojectenv/lib/python3.12/site-packages (from pandas>=1.3.5->realtabformer) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./newprojectenv/lib/python3.12/site-packages (from pandas>=1.3.5->realtabformer) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./newprojectenv/lib/python3.12/site-packages (from pandas>=1.3.5->realtabformer) (2025.1)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn>=1.0.2->realtabformer)\n",
            "  Downloading scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn>=1.0.2->realtabformer)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0.2->realtabformer)\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.46.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.46.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers>=4.46.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Using cached sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting protobuf (from transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Downloading protobuf-6.30.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: torch>=2.0 in ./newprojectenv/lib/python3.12/site-packages (from transformers[sentencepiece,torch]>=4.46.0->realtabformer) (2.6.0)\n",
            "Collecting accelerate>=0.26.0 (from transformers[sentencepiece,torch]>=4.46.0->realtabformer)\n",
            "  Using cached accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: psutil in ./newprojectenv/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (7.0.0)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.6.1->realtabformer)\n",
            "  Downloading aiohappyeyeballs-2.5.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.6.1->realtabformer)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./newprojectenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.6.1->realtabformer) (25.1.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.6.1->realtabformer)\n",
            "  Using cached frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.6.1->realtabformer)\n",
            "  Using cached multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.6.1->realtabformer)\n",
            "  Using cached propcache-0.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.6.1->realtabformer)\n",
            "  Using cached yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (69 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./newprojectenv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets>=2.6.1->realtabformer) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in ./newprojectenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->realtabformer) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./newprojectenv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.6.1->realtabformer) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./newprojectenv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.6.1->realtabformer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./newprojectenv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.6.1->realtabformer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./newprojectenv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.6.1->realtabformer) (2025.1.31)\n",
            "Requirement already satisfied: networkx in ./newprojectenv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./newprojectenv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (3.1.6)\n",
            "Requirement already satisfied: setuptools in ./newprojectenv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (75.8.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./newprojectenv/lib/python3.12/site-packages (from torch>=2.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./newprojectenv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./newprojectenv/lib/python3.12/site-packages (from jinja2->torch>=2.0->transformers[sentencepiece,torch]>=4.46.0->realtabformer) (3.0.2)\n",
            "Using cached realtabformer-0.2.2-py3-none-any.whl (49 kB)\n",
            "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached shapely-2.0.7-cp312-cp312-macosx_11_0_arm64.whl (1.3 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "Using cached accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Using cached aiohttp-3.11.13-cp312-cp312-macosx_11_0_arm64.whl (456 kB)\n",
            "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "Downloading pyarrow-19.0.1-cp312-cp312-macosx_12_0_arm64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "Downloading scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl (22.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
            "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "Downloading protobuf-6.30.0-cp39-abi3-macosx_10_9_universal2.whl (417 kB)\n",
            "Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
            "Downloading aiohappyeyeballs-2.5.0-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
            "Using cached multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
            "Using cached propcache-0.3.0-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
            "Using cached yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl (92 kB)\n",
            "Installing collected packages: sentencepiece, xxhash, tqdm, threadpoolctl, shapely, scipy, safetensors, regex, pyarrow, protobuf, propcache, multidict, joblib, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, scikit-learn, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, datasets, realtabformer\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "Successfully installed accelerate-1.4.0 aiohappyeyeballs-2.5.0 aiohttp-3.11.13 aiosignal-1.3.2 datasets-3.3.2 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.2 joblib-1.4.2 multidict-6.1.0 multiprocess-0.70.16 propcache-0.3.0 protobuf-6.30.0 pyarrow-19.0.1 realtabformer-0.2.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentencepiece-0.2.0 shapely-2.0.7 threadpoolctl-3.5.0 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.49.0 xxhash-3.5.0 yarl-1.18.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install realtabformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vM904kzBDEYo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ads_df_minimal = pd.read_csv(\"train_ads_minimal_user.csv\")\n",
        "feeds_df_minimal = pd.read_csv(\"train_feeds_minimal_user.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8VvRLE9FhI_",
        "outputId": "e3417a1c-7923-4cdc-926b-f11734018fa3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7675517, 18), (3227732, 16))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ads_df_minimal.shape, feeds_df_minimal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6yClxqDJJDs0"
      },
      "outputs": [],
      "source": [
        "feeds_df_minimal.rename(columns={'u_userId': 'user_id'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvO8DKJzFrOc",
        "outputId": "252e45e1-49db-4a1f-b820-d4c2c7bcca43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Index(['label', 'user_id', 'age', 'gender', 'residence', 'city_rank',\n",
              "        'series_dev', 'series_group', 'emui_dev', 'net_type', 'creat_type_cd',\n",
              "        'inter_type_cd', 'slot_id', 'hispace_app_tags', 'app_second_class',\n",
              "        'app_score', 'u_refreshTimes', 'u_feedLifeCycle'],\n",
              "       dtype='object'),\n",
              " Index(['user_id', 'u_phonePrice', 'u_browserLifeCycle', 'u_browserMode',\n",
              "        'u_feedLifeCycle', 'u_refreshTimes', 'i_dislikeTimes', 'i_upTimes',\n",
              "        'i_dtype', 'e_ch', 'e_po', 'e_rn', 'e_section', 'label', 'cillabel',\n",
              "        'pro'],\n",
              "       dtype='object'))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ads_df_minimal.columns, feeds_df_minimal.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QISAcjIaFkxL",
        "outputId": "96ef411b-0d1b-4c6d-b305-1d27e712bf49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(label\n",
              " 0    7556381\n",
              " 1     119136\n",
              " Name: count, dtype: int64,\n",
              " label\n",
              " -1    2911971\n",
              "  1     315761\n",
              " Name: count, dtype: int64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ads_df_minimal['label'].value_counts(), feeds_df_minimal['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IDpPIH3oWnap"
      },
      "outputs": [],
      "source": [
        "ads_df_minimal_label1 = ads_df_minimal[ads_df_minimal['label']==1]\n",
        "feeds_df_minimal_label1 = feeds_df_minimal[feeds_df_minimal['label']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOjyNBjjWt8K",
        "outputId": "b9cb7230-53a4-43d1-dd6a-ab74ebc4b474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(label\n",
              " 1    119136\n",
              " Name: count, dtype: int64,\n",
              " label\n",
              " 1    315761\n",
              " Name: count, dtype: int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ads_df_minimal_label1['label'].value_counts(), feeds_df_minimal_label1['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X3DKLxz9XjaU"
      },
      "outputs": [],
      "source": [
        "ads_df_minimal_label1.to_csv('ads_df_minimal_label1.csv', index=False)\n",
        "feeds_df_minimal_label1.to_csv('feeds_df_minimal_label1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((119136, 18), (315761, 16))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ads_df_minimal_label1.shape, feeds_df_minimal_label1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "b074cd6742dd43ba8fbf1d7f11666cad",
            "a85b8ef1259a4e96a1c37916772ba5eb",
            "ee38ea9978ff4f50b3ff9c58f9224dc4",
            "4865076025c24795b4b257f16593af0b",
            "a6001d4441884255b59485c32136cd9c",
            "c6b1fa4f4bf24bd29756c1334568ba62",
            "78c253aca89a4facb5b86e9ad1699538",
            "5b22509d7b314f2c9c1ba815270583b2",
            "5ad1e0ab4ca24abc9368e60dc50e0af9",
            "24e85205297c42b0a4685e0c767da0e0",
            "6912c9b8f315476f9591264cd534670f"
          ]
        },
        "id": "gKVSklj6Bj4z",
        "outputId": "ca8fd171-7599-4c6c-fcc6-6f48adc328a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/realtabformer/realtabformer.py:77: UserWarning: The device=cuda is not available, using device=cpu instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/realtabformer/realtabformer.py:536: UserWarning: The frac (0.165) set results to a sample larger than                     frac_max_data=10000. Setting frac to 0.001302843834493494.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the sensitivity threshold...\n",
            "Using parallel computation!!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/realtabformer/realtabformer.py:560: UserWarning: The qt_max (0.05) set is lower than the duplicate \rate (0.7664892149935959) in                     the data. This will not give a reliable early stopping condition. Consider                         using qt_max=\"compute\" argument.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b074cd6742dd43ba8fbf1d7f11666cad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Bootstrap round:   0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensitivity threshold summary:\n",
            "count    500.000000\n",
            "mean       0.037246\n",
            "std        0.001661\n",
            "min        0.033011\n",
            "25%        0.036250\n",
            "50%        0.037246\n",
            "75%        0.038325\n",
            "max        0.043021\n",
            "dtype: float64\n",
            "Sensitivity threshold: 0.039935252259644886 qt_max: 0.05\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "from realtabformer import REaLTabFormer\n",
        "\n",
        "\n",
        "join_on = \"user_id\"  # This is the common key in both datasets\n",
        "\n",
        "# ----- Parent Modeling (Ads) -----\n",
        "# Remove the unique identifier from features to be modeled\n",
        "ads_model = REaLTabFormer(model_type=\"tabular\")\n",
        "ads_model.fit(ads_df_minimal.drop(join_on, axis=1))\n",
        "ads_model.save(\"rtf_ads/\")\n",
        "\n",
        "# Retrieve the most recent saved model directory for the parent\n",
        "ads_model_path = sorted([\n",
        "    p for p in Path(\"rtf_ads/\").glob(\"id*\") if p.is_dir()\n",
        "], key=os.path.getmtime)[-1]\n",
        "\n",
        "# ----- Child Modeling (Feeds) -----\n",
        "feeds_model = REaLTabFormer(\n",
        "    model_type=\"relational\",\n",
        "    parent_realtabformer_path=ads_model_path,\n",
        "    train_size=0.8\n",
        ")\n",
        "\n",
        "# Fit the relational model using both the child and parent data\n",
        "feeds_model.fit(\n",
        "    df=feeds_df_minimal,\n",
        "    in_df=ads_df_minimal,\n",
        "    join_on=join_on\n",
        ")\n",
        "\n",
        "# ----- Generating Synthetic Data -----\n",
        "# Generate synthetic ads data from the parent model\n",
        "synthetic_ads = ads_model.sample(n_samples=len(ads_df_minimal))\n",
        "# Ensure the synthetic ads data contains the join key (or recreate it as needed)\n",
        "synthetic_ads.index.name = join_on\n",
        "synthetic_ads = synthetic_ads.reset_index()\n",
        "\n",
        "# Generate synthetic feeds data using the relational model\n",
        "synthetic_feeds = feeds_model.sample(\n",
        "    input_unique_ids=synthetic_ads[join_on],\n",
        "    input_df=synthetic_ads.drop(join_on, axis=1),\n",
        "    gen_batch=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "EXQAppv9XJPR",
        "outputId": "2aa91725-1c8b-4139-b329-014f1b2851e1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'synthetic_ads' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1d1bcacf1ac7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msynthetic_ads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'synthetic_ads' is not defined"
          ]
        }
      ],
      "source": [
        "synthetic_ads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrTtiaaOXY5G"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:77: UserWarning: The device=cuda is not available, using device=mps instead.\n",
            "  warnings.warn(\n",
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:536: UserWarning: The frac (0.165) set results to a sample larger than                     frac_max_data=10000. Setting frac to 0.08393768466290626.\n",
            "  warnings.warn(\n",
            "ate (0.2197236771420897) in                     the data. This will not give a reliable early stopping condition. Consider                         using qt_max=\"compute\" argument.uplicate \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the sensitivity threshold...\n",
            "Using parallel computation!!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bootstrap round: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [28:22<00:00,  3.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensitivity threshold summary:\n",
            "count    500.000000\n",
            "mean       0.049615\n",
            "std        0.001666\n",
            "min        0.042790\n",
            "25%        0.048437\n",
            "50%        0.049663\n",
            "75%        0.050703\n",
            "max        0.054119\n",
            "dtype: float64\n",
            "Sensitivity threshold: 0.05225801965582736 qt_max: 0.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119136/119136 [00:12<00:00, 9885.74 examples/s] \n",
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18615' max='18615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18615/18615 36:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.039500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.740500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.705900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.686400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.682800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.659000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.658000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.660100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.658300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.647600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.647400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.647700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.645400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.642000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.646600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.644200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.641800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.640800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.639200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.642200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.635800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.639200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.635200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.639100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.636800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.636900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.629200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.633700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.632800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.635700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.635000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.635800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.632400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.632700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.634000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.629400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.630200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.630700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.634200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.632600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.630500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.626600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.630500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.627300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.628600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.628100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.629000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.626700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.625600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.625900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.627800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.628200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.625100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.626700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.623500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.628000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.623700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.625200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.630800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.627400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.627000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.624200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.626300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.623800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.624800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.626100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.622800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.621600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.622700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.616300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.626800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.622600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.621700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.623100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.621800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.626100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.620800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.622200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.623400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.622500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.619400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.624800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.623700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.619000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.621500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.618900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.624000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.619200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.620200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.615000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.619300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.619500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.622900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.618000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.618000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.620900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.619700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.620300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.613100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10700</td>\n",
              "      <td>0.619200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.624000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10900</td>\n",
              "      <td>0.619300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.620800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11100</td>\n",
              "      <td>0.622800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>0.618300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11300</td>\n",
              "      <td>0.617400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.621300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.614500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11700</td>\n",
              "      <td>0.615700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.619100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11900</td>\n",
              "      <td>0.614600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.617200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12100</td>\n",
              "      <td>0.618800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.620500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12300</td>\n",
              "      <td>0.615100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.617600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.621900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12700</td>\n",
              "      <td>0.616700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.620200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12900</td>\n",
              "      <td>0.616700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.617700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13100</td>\n",
              "      <td>0.615800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.616200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13300</td>\n",
              "      <td>0.612000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13400</td>\n",
              "      <td>0.618100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.616400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13700</td>\n",
              "      <td>0.614500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.619700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13900</td>\n",
              "      <td>0.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.620600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14100</td>\n",
              "      <td>0.616600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14200</td>\n",
              "      <td>0.614500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14300</td>\n",
              "      <td>0.617200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.616700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14600</td>\n",
              "      <td>0.616100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14700</td>\n",
              "      <td>0.614100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14800</td>\n",
              "      <td>0.615300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14900</td>\n",
              "      <td>0.616200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.619700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15100</td>\n",
              "      <td>0.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15200</td>\n",
              "      <td>0.617700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15300</td>\n",
              "      <td>0.616500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15400</td>\n",
              "      <td>0.615100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.612200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.611100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15700</td>\n",
              "      <td>0.613100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15800</td>\n",
              "      <td>0.613600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15900</td>\n",
              "      <td>0.615800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.612300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16100</td>\n",
              "      <td>0.618300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16200</td>\n",
              "      <td>0.612100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16300</td>\n",
              "      <td>0.617400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16400</td>\n",
              "      <td>0.614600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.615600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16600</td>\n",
              "      <td>0.612200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16700</td>\n",
              "      <td>0.613700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16800</td>\n",
              "      <td>0.613900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16900</td>\n",
              "      <td>0.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.617000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17100</td>\n",
              "      <td>0.612300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17200</td>\n",
              "      <td>0.610500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17300</td>\n",
              "      <td>0.612700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17400</td>\n",
              "      <td>0.614300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.613200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17600</td>\n",
              "      <td>0.611300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17700</td>\n",
              "      <td>0.612500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17800</td>\n",
              "      <td>0.612100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17900</td>\n",
              "      <td>0.615200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.609300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18100</td>\n",
              "      <td>0.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18200</td>\n",
              "      <td>0.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18300</td>\n",
              "      <td>0.614800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18400</td>\n",
              "      <td>0.613500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.615800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18600</td>\n",
              "      <td>0.613600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30080it [02:59, 167.88it/s]                           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 5,                     sensitivity_threshold: 0.05225801965582736,                         val_sensitivity: -0.0010377478672504803,                             val_sensitivities: [np.float64(-0.0020007895855688063), np.float64(-0.0003823124848288695), np.float64(-0.0014965483733830006), np.float64(-0.002011029039765253), np.float64(-0.0015427351292274672), np.float64(-3.593772144722639e-05), np.float64(0.0004820936639118465), np.float64(-0.00047441116309212606), np.float64(-0.00031564760959001113), np.float64(9.62688230883045e-06), np.float64(-0.0024226178434149283), np.float64(-0.0014133738601823705), np.float64(-0.001705591872255165), np.float64(-0.0012603468863208581), np.float64(-0.0009965969859017983)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37230' max='37230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37230/37230 35:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>18700</td>\n",
              "      <td>0.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18800</td>\n",
              "      <td>0.611300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18900</td>\n",
              "      <td>0.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.612400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19100</td>\n",
              "      <td>0.609200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19200</td>\n",
              "      <td>0.608100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19300</td>\n",
              "      <td>0.610400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19400</td>\n",
              "      <td>0.614700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.610300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19600</td>\n",
              "      <td>0.612600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19700</td>\n",
              "      <td>0.611100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19800</td>\n",
              "      <td>0.610800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19900</td>\n",
              "      <td>0.609200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.610900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20100</td>\n",
              "      <td>0.610300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20200</td>\n",
              "      <td>0.610500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20300</td>\n",
              "      <td>0.612000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20400</td>\n",
              "      <td>0.608800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>0.612700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20600</td>\n",
              "      <td>0.612100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20700</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20800</td>\n",
              "      <td>0.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20900</td>\n",
              "      <td>0.613500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.615500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21100</td>\n",
              "      <td>0.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21200</td>\n",
              "      <td>0.612300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21300</td>\n",
              "      <td>0.608600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21400</td>\n",
              "      <td>0.608400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.610500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21600</td>\n",
              "      <td>0.611500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21700</td>\n",
              "      <td>0.609300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21800</td>\n",
              "      <td>0.610600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21900</td>\n",
              "      <td>0.610700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.608100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22100</td>\n",
              "      <td>0.614700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22200</td>\n",
              "      <td>0.612600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22300</td>\n",
              "      <td>0.612400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22400</td>\n",
              "      <td>0.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.604900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22600</td>\n",
              "      <td>0.608300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22700</td>\n",
              "      <td>0.606400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22800</td>\n",
              "      <td>0.607900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22900</td>\n",
              "      <td>0.605300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23100</td>\n",
              "      <td>0.609200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23200</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23300</td>\n",
              "      <td>0.612000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23400</td>\n",
              "      <td>0.607500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>0.610300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23600</td>\n",
              "      <td>0.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23700</td>\n",
              "      <td>0.605900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23800</td>\n",
              "      <td>0.610300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23900</td>\n",
              "      <td>0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24100</td>\n",
              "      <td>0.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24200</td>\n",
              "      <td>0.611700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24300</td>\n",
              "      <td>0.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24400</td>\n",
              "      <td>0.610700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24600</td>\n",
              "      <td>0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24700</td>\n",
              "      <td>0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24800</td>\n",
              "      <td>0.613300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24900</td>\n",
              "      <td>0.606300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25100</td>\n",
              "      <td>0.603700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25200</td>\n",
              "      <td>0.608900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25300</td>\n",
              "      <td>0.614700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25400</td>\n",
              "      <td>0.607200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25600</td>\n",
              "      <td>0.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25700</td>\n",
              "      <td>0.611100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25800</td>\n",
              "      <td>0.606300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25900</td>\n",
              "      <td>0.606100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26100</td>\n",
              "      <td>0.605800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26200</td>\n",
              "      <td>0.601600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26300</td>\n",
              "      <td>0.605100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26400</td>\n",
              "      <td>0.605200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26500</td>\n",
              "      <td>0.605500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26600</td>\n",
              "      <td>0.603400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26700</td>\n",
              "      <td>0.604200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26800</td>\n",
              "      <td>0.608700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26900</td>\n",
              "      <td>0.607000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27000</td>\n",
              "      <td>0.610700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27100</td>\n",
              "      <td>0.606900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27200</td>\n",
              "      <td>0.603300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27300</td>\n",
              "      <td>0.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27400</td>\n",
              "      <td>0.604500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27500</td>\n",
              "      <td>0.605300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27600</td>\n",
              "      <td>0.604800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27700</td>\n",
              "      <td>0.605200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27800</td>\n",
              "      <td>0.607400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27900</td>\n",
              "      <td>0.607100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>0.608700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28100</td>\n",
              "      <td>0.609300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28200</td>\n",
              "      <td>0.605500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28300</td>\n",
              "      <td>0.605200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28400</td>\n",
              "      <td>0.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28500</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28600</td>\n",
              "      <td>0.604000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28700</td>\n",
              "      <td>0.603800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28800</td>\n",
              "      <td>0.604700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28900</td>\n",
              "      <td>0.599900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29000</td>\n",
              "      <td>0.606300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29100</td>\n",
              "      <td>0.608600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29200</td>\n",
              "      <td>0.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29300</td>\n",
              "      <td>0.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29400</td>\n",
              "      <td>0.606000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29500</td>\n",
              "      <td>0.604500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29600</td>\n",
              "      <td>0.607800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29700</td>\n",
              "      <td>0.604900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29800</td>\n",
              "      <td>0.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29900</td>\n",
              "      <td>0.601200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.601200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30100</td>\n",
              "      <td>0.603100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30200</td>\n",
              "      <td>0.598600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30300</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30400</td>\n",
              "      <td>0.601300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30500</td>\n",
              "      <td>0.603900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30600</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30700</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30800</td>\n",
              "      <td>0.599900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30900</td>\n",
              "      <td>0.602500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31000</td>\n",
              "      <td>0.603800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31100</td>\n",
              "      <td>0.601800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31200</td>\n",
              "      <td>0.599100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31300</td>\n",
              "      <td>0.600100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31400</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31500</td>\n",
              "      <td>0.603000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31600</td>\n",
              "      <td>0.602100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31700</td>\n",
              "      <td>0.603600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31800</td>\n",
              "      <td>0.604900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31900</td>\n",
              "      <td>0.599600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.602500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32100</td>\n",
              "      <td>0.601100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32200</td>\n",
              "      <td>0.606600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32300</td>\n",
              "      <td>0.599600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32400</td>\n",
              "      <td>0.608500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32500</td>\n",
              "      <td>0.606400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32600</td>\n",
              "      <td>0.605000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32700</td>\n",
              "      <td>0.603600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32800</td>\n",
              "      <td>0.599500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32900</td>\n",
              "      <td>0.606600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.606700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33100</td>\n",
              "      <td>0.602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33200</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33300</td>\n",
              "      <td>0.603500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33400</td>\n",
              "      <td>0.602700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33500</td>\n",
              "      <td>0.598300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33600</td>\n",
              "      <td>0.598400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33700</td>\n",
              "      <td>0.597400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33800</td>\n",
              "      <td>0.599100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33900</td>\n",
              "      <td>0.597400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.600100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34100</td>\n",
              "      <td>0.601200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34200</td>\n",
              "      <td>0.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34300</td>\n",
              "      <td>0.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34400</td>\n",
              "      <td>0.597800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34500</td>\n",
              "      <td>0.599300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34600</td>\n",
              "      <td>0.601400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34700</td>\n",
              "      <td>0.600700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34800</td>\n",
              "      <td>0.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34900</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.599000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35100</td>\n",
              "      <td>0.596500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35200</td>\n",
              "      <td>0.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35300</td>\n",
              "      <td>0.596500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35400</td>\n",
              "      <td>0.595500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35500</td>\n",
              "      <td>0.600300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35600</td>\n",
              "      <td>0.597700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35700</td>\n",
              "      <td>0.600600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35800</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35900</td>\n",
              "      <td>0.602200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.598300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36100</td>\n",
              "      <td>0.596600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36200</td>\n",
              "      <td>0.598700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36300</td>\n",
              "      <td>0.600300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36400</td>\n",
              "      <td>0.601200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36500</td>\n",
              "      <td>0.602000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36600</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36700</td>\n",
              "      <td>0.601600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36800</td>\n",
              "      <td>0.602700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36900</td>\n",
              "      <td>0.601100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>0.601700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37100</td>\n",
              "      <td>0.600500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37200</td>\n",
              "      <td>0.598200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30080it [02:54, 171.89it/s]                           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 10,                     sensitivity_threshold: 0.05225801965582736,                         val_sensitivity: 0.0033107662157731014,                             val_sensitivities: [np.float64(0.0019003712494674698), np.float64(0.0035986460740200254), np.float64(0.002618931743521109), np.float64(0.0022241127856101133), np.float64(0.002574461182863286), np.float64(0.004836225068915194), np.float64(0.004039327894800925), np.float64(0.0035963630459490176), np.float64(0.004610073111291633), np.float64(0.0031387039142439493), np.float64(0.0030192062237889743), np.float64(0.0031569965870307153), np.float64(0.00352621327706541), np.float64(0.00236474836196929), np.float64(0.0044571127160594)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47600' max='55845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47600/55845 20:26 < 16:15, 8.45 it/s, Epoch 12.79/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>37300</td>\n",
              "      <td>0.595700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37400</td>\n",
              "      <td>0.593100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37500</td>\n",
              "      <td>0.591800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37600</td>\n",
              "      <td>0.595700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37700</td>\n",
              "      <td>0.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37800</td>\n",
              "      <td>0.596100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37900</td>\n",
              "      <td>0.594300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>0.593200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38100</td>\n",
              "      <td>0.595600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38200</td>\n",
              "      <td>0.597200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38300</td>\n",
              "      <td>0.595300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38400</td>\n",
              "      <td>0.593900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38500</td>\n",
              "      <td>0.594900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38600</td>\n",
              "      <td>0.593800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38700</td>\n",
              "      <td>0.595300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38800</td>\n",
              "      <td>0.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38900</td>\n",
              "      <td>0.597000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>0.596100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39100</td>\n",
              "      <td>0.597500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39200</td>\n",
              "      <td>0.597400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39300</td>\n",
              "      <td>0.595200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39400</td>\n",
              "      <td>0.596900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39500</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39600</td>\n",
              "      <td>0.595500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39700</td>\n",
              "      <td>0.595800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39800</td>\n",
              "      <td>0.593200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39900</td>\n",
              "      <td>0.597500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.600100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40100</td>\n",
              "      <td>0.595500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40200</td>\n",
              "      <td>0.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40300</td>\n",
              "      <td>0.595200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40400</td>\n",
              "      <td>0.593600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40500</td>\n",
              "      <td>0.592800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40600</td>\n",
              "      <td>0.597200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40700</td>\n",
              "      <td>0.597500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40800</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40900</td>\n",
              "      <td>0.596800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>0.593400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41100</td>\n",
              "      <td>0.589600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41200</td>\n",
              "      <td>0.587200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41300</td>\n",
              "      <td>0.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41400</td>\n",
              "      <td>0.590600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41500</td>\n",
              "      <td>0.593900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41600</td>\n",
              "      <td>0.594300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41700</td>\n",
              "      <td>0.591900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41800</td>\n",
              "      <td>0.591000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41900</td>\n",
              "      <td>0.593300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>0.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42100</td>\n",
              "      <td>0.591000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42200</td>\n",
              "      <td>0.592600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42300</td>\n",
              "      <td>0.593100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42400</td>\n",
              "      <td>0.593000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42500</td>\n",
              "      <td>0.588800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42600</td>\n",
              "      <td>0.590900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42700</td>\n",
              "      <td>0.591700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42800</td>\n",
              "      <td>0.587400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42900</td>\n",
              "      <td>0.593300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>0.593000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43100</td>\n",
              "      <td>0.594000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43200</td>\n",
              "      <td>0.592700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43300</td>\n",
              "      <td>0.591800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43400</td>\n",
              "      <td>0.589600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43500</td>\n",
              "      <td>0.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43600</td>\n",
              "      <td>0.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43700</td>\n",
              "      <td>0.596300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43800</td>\n",
              "      <td>0.591000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43900</td>\n",
              "      <td>0.592900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>0.590700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44100</td>\n",
              "      <td>0.594900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44200</td>\n",
              "      <td>0.593900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44300</td>\n",
              "      <td>0.591700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44400</td>\n",
              "      <td>0.592400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44500</td>\n",
              "      <td>0.593000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44600</td>\n",
              "      <td>0.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44700</td>\n",
              "      <td>0.592600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44800</td>\n",
              "      <td>0.585800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44900</td>\n",
              "      <td>0.586600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.586500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45100</td>\n",
              "      <td>0.587300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45200</td>\n",
              "      <td>0.586700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45300</td>\n",
              "      <td>0.586700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45400</td>\n",
              "      <td>0.590100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45500</td>\n",
              "      <td>0.585600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45600</td>\n",
              "      <td>0.586600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45700</td>\n",
              "      <td>0.588300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45800</td>\n",
              "      <td>0.586900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45900</td>\n",
              "      <td>0.585700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>0.589400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46100</td>\n",
              "      <td>0.588800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46200</td>\n",
              "      <td>0.591500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46300</td>\n",
              "      <td>0.586300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46400</td>\n",
              "      <td>0.586200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46500</td>\n",
              "      <td>0.585900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46600</td>\n",
              "      <td>0.587400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46700</td>\n",
              "      <td>0.589800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46800</td>\n",
              "      <td>0.588000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46900</td>\n",
              "      <td>0.586900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47000</td>\n",
              "      <td>0.586300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47100</td>\n",
              "      <td>0.590600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47200</td>\n",
              "      <td>0.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47300</td>\n",
              "      <td>0.589400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47400</td>\n",
              "      <td>0.589400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47500</td>\n",
              "      <td>0.589300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Initialize and fit the parent model in tabular mode.\u001b[39;00m\n\u001b[32m     20\u001b[39m parent_model = REaLTabFormer(model_type=\u001b[33m\"\u001b[39m\u001b[33mtabular\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m                              gradient_accumulation_steps=\u001b[32m4\u001b[39m,\n\u001b[32m     22\u001b[39m                              logging_steps=\u001b[32m100\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mparent_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Save the parent model (this creates a folder with a unique experiment id)\u001b[39;00m\n\u001b[32m     26\u001b[39m parent_model.save(\u001b[33m\"\u001b[39m\u001b[33mrtf_ads/\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:458\u001b[39m, in \u001b[36mREaLTabFormer.fit\u001b[39m\u001b[34m(self, df, in_df, join_on, resume_from_checkpoint, device, num_bootstrap, frac, frac_max_data, qt_max, qt_max_default, qt_interval, qt_interval_unique, distance, quantile, n_critic, n_critic_stop, gen_rounds, sensitivity_max_col_nums, use_ks, full_sensitivity, sensitivity_orig_frac_multiple, orig_samples_rounds, load_from_best_mean_sensitivity, target_col)\u001b[39m\n\u001b[32m    456\u001b[39m         trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m         trainer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_with_sensitivity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfrac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfrac_max_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrac_max_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_max\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_max_default\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_max_default\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_interval_unique\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_interval_unique\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_critic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_critic_stop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_critic_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgen_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m            \u001b[49m\u001b[43msensitivity_max_col_nums\u001b[49m\u001b[43m=\u001b[49m\u001b[43msensitivity_max_col_nums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_ks\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_ks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfull_sensitivity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_sensitivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m            \u001b[49m\u001b[43msensitivity_orig_frac_multiple\u001b[49m\u001b[43m=\u001b[49m\u001b[43msensitivity_orig_frac_multiple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m            \u001b[49m\u001b[43morig_samples_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43morig_samples_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mload_from_best_mean_sensitivity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_from_best_mean_sensitivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == ModelType.relational:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:710\u001b[39m, in \u001b[36mREaLTabFormer._train_with_sensitivity\u001b[39m\u001b[34m(self, df, device, num_bootstrap, frac, frac_max_data, qt_max, qt_max_default, qt_interval, qt_interval_unique, distance, quantile, n_critic, n_critic_stop, gen_rounds, sensitivity_max_col_nums, use_ks, resume_from_checkpoint, full_sensitivity, sensitivity_orig_frac_multiple, orig_samples_rounds, load_from_best_mean_sensitivity)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     trainer = \u001b[38;5;28mself\u001b[39m._build_tabular_trainer(\n\u001b[32m    706\u001b[39m         device=device,\n\u001b[32m    707\u001b[39m         num_train_epochs=num_train_epochs,\n\u001b[32m    708\u001b[39m         target_epochs=\u001b[38;5;28mself\u001b[39m.epochs,\n\u001b[32m    709\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    713\u001b[39m     \u001b[38;5;66;03m# Generate samples\u001b[39;00m\n\u001b[32m    714\u001b[39m     gen_df = \u001b[38;5;28mself\u001b[39m.sample(n_samples=gen_rounds * gen_total, device=device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:2612\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2610\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2611\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2612\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m   2614\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2615\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2616\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:3092\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[39m\n\u001b[32m   3089\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3092\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3093\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:3194\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;28mself\u001b[39m.save_model(output_dir, _internal_call=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3193\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3194\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3195\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_scaler(output_dir)\n\u001b[32m   3196\u001b[39m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:3316\u001b[39m, in \u001b[36mTrainer._save_optimizer_and_scheduler\u001b[39m\u001b[34m(self, output_dir)\u001b[39m\n\u001b[32m   3311\u001b[39m     save_fsdp_optimizer(\n\u001b[32m   3312\u001b[39m         \u001b[38;5;28mself\u001b[39m.accelerator.state.fsdp_plugin, \u001b[38;5;28mself\u001b[39m.accelerator, \u001b[38;5;28mself\u001b[39m.optimizer, \u001b[38;5;28mself\u001b[39m.model, output_dir\n\u001b[32m   3313\u001b[39m     )\n\u001b[32m   3314\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m   3315\u001b[39m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3316\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3318\u001b[39m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[32m   3319\u001b[39m is_deepspeed_custom_scheduler = \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3320\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[32m   3321\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/torch/serialization.py:944\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/torch/serialization.py:1216\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1214\u001b[39m     storage = storage.cpu()\n\u001b[32m   1215\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1216\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "from realtabformer import REaLTabFormer\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load Your Datasets\n",
        "# ---------------------------\n",
        "# Replace these file paths with your actual CSV files.\n",
        "ads_df = pd.read_csv(\"ads_df_minimal_label1.csv\")    # Contains only label 1 rows for ads\n",
        "feeds_df = pd.read_csv(\"feeds_df_minimal_label1.csv\")  # Contains only label 1 rows for feeds\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Train the Parent Model (Ads Data)\n",
        "# ---------------------------\n",
        "# Since \"user_id\" is used for joining, remove it from the features to be modeled.\n",
        "parent_features = ads_df.drop(columns=[\"user_id\"])\n",
        "\n",
        "# Initialize and fit the parent model in tabular mode.\n",
        "parent_model = REaLTabFormer(model_type=\"tabular\",\n",
        "                             gradient_accumulation_steps=4,\n",
        "                             logging_steps=100)\n",
        "parent_model.fit(parent_features)\n",
        "\n",
        "# Save the parent model (this creates a folder with a unique experiment id)\n",
        "parent_model.save(\"rtf_ads/\")\n",
        "\n",
        "# Retrieve the path of the saved parent model (assumes the most recent is the one we need)\n",
        "parent_model_path = sorted([p for p in Path(\"rtf_ads/\").glob(\"id*\") if p.is_dir()],\n",
        "                           key=os.path.getmtime)[-1]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Train the Child Model (Feeds Data)\n",
        "# ---------------------------\n",
        "# The child (relational) model uses the feeds data.\n",
        "# It also takes the original ads data for relational joining via \"user_id.\"\n",
        "child_model = REaLTabFormer(model_type=\"relational\",\n",
        "                            parent_realtabformer_path=parent_model_path,\n",
        "                            train_size=0.8)  # You can adjust train_size as needed\n",
        "\n",
        "# Fit the child model.\n",
        "child_model.fit(\n",
        "    df=feeds_df,\n",
        "    in_df=ads_df,    # The parent table used for the join\n",
        "    join_on=\"user_id\"\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Generate Synthetic Samples\n",
        "# ---------------------------\n",
        "# Generate synthetic parent samples (for ads data)\n",
        "synthetic_ads = parent_model.sample(n_samples=len(ads_df))\n",
        "\n",
        "# Since we dropped \"user_id\" before training, you might need to reassign or generate new ids.\n",
        "# Here, we simply reset the index to create a new \"user_id\" column.\n",
        "synthetic_ads.index.name = \"user_id\"\n",
        "synthetic_ads = synthetic_ads.reset_index()\n",
        "\n",
        "# Generate synthetic child samples (for feeds data) using the relational model.\n",
        "synthetic_feeds = child_model.sample(\n",
        "    input_unique_ids=synthetic_ads[\"user_id\"],\n",
        "    input_df=synthetic_ads.drop(columns=[\"user_id\"]),\n",
        "    gen_batch=64  # Adjust batch size if needed\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Display Sample Outputs\n",
        "# ---------------------------\n",
        "print(\"Synthetic Ads Samples:\")\n",
        "print(synthetic_ads.head())\n",
        "\n",
        "print(\"\\nSynthetic Feeds Samples:\")\n",
        "print(synthetic_feeds.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "119136"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ads_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:77: UserWarning: The device=cuda is not available, using device=mps instead.\n",
            "  warnings.warn(\n",
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:536: UserWarning: The frac (0.165) set results to a sample larger than                     frac_max_data=10000. Setting frac to 0.08393768466290626.\n",
            "  warnings.warn(\n",
            "ate (0.2197236771420897) in                     the data. This will not give a reliable early stopping condition. Consider                         using qt_max=\"compute\" argument.uplicate \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the sensitivity threshold...\n",
            "Using parallel computation!!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Bootstrap round: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [28:02<00:00,  3.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensitivity threshold summary:\n",
            "count    500.000000\n",
            "mean       0.049724\n",
            "std        0.001777\n",
            "min        0.044984\n",
            "25%        0.048514\n",
            "50%        0.049688\n",
            "75%        0.050957\n",
            "max        0.053720\n",
            "dtype: float64\n",
            "Sensitivity threshold: 0.05274019980209938 qt_max: 0.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119136/119136 [00:13<00:00, 9159.29 examples/s]\n",
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='580' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [580/580 23:01, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.692000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30080it [03:02, 164.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 5,                     sensitivity_threshold: 0.05274019980209938,                         val_sensitivity: -0.00016023419097077601,                             val_sensitivities: [np.float64(0.0009398115310568447), np.float64(0.0008769174653995032), np.float64(0.0005390794571677788), np.float64(3.24044069993519e-05), np.float64(-0.0006290263765649698), np.float64(0.0007993965290293853), np.float64(0.0013360479721243063), np.float64(0.00036158489648746047), np.float64(4.4106016669034426e-05), np.float64(0.00046338498936493634), np.float64(-0.001743714928185076), np.float64(-0.001744657556465674), np.float64(-0.0015390542623083796), np.float64(-0.0014529464213341985), np.float64(-0.0006868465840019438)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1160' max='1160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1160/1160 23:16, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.620300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30080it [03:03, 163.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 10,                     sensitivity_threshold: 0.05274019980209938,                         val_sensitivity: -0.001964815246219711,                             val_sensitivities: [np.float64(-5.565562324177584e-06), np.float64(-0.0005089638407778775), np.float64(-0.001558067914741874), np.float64(-0.001715958974773937), np.float64(-0.0011071435796799465), np.float64(-0.0013946761600388356), np.float64(-0.0018556920026704968), np.float64(-0.0016594465475009614), np.float64(-0.0017908135366668679), np.float64(-0.000843356416798282), np.float64(-0.00345456018143528), np.float64(-0.0033503273803490705), np.float64(-0.0037363304981774003), np.float64(-0.0030816367871974084), np.float64(-0.003409689310163244)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1740/1740 23:20, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.613800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30080it [03:03, 163.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 15,                     sensitivity_threshold: 0.05274019980209938,                         val_sensitivity: 0.001717876615130583,                             val_sensitivities: [np.float64(0.0031396243998298243), np.float64(0.002017159547280029), np.float64(0.001536822884966525), np.float64(0.0014580254661025528), np.float64(0.0017330943556716682), np.float64(0.0017735990440893522), np.float64(0.002657980521978577), np.float64(0.002329821717990276), np.float64(0.0024028132473955157), np.float64(0.002758079221963329), np.float64(0.0007137646653563259), np.float64(0.0008905581574519), np.float64(-0.00027483672061985446), np.float64(0.0014731518456205773), np.float64(0.0011584908718821566)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2320/2320 23:04, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.608900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30080it [02:54, 172.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 20,                     sensitivity_threshold: 0.05274019980209938,                         val_sensitivity: 0.002840641599242172,                             val_sensitivities: [np.float64(0.004709997972013791), np.float64(0.003521583901330735), np.float64(0.0025255449245332857), np.float64(0.002603818325530491), np.float64(0.0030250643846450238), np.float64(0.00292854828256643), np.float64(0.0036669367909238234), np.float64(0.0033131675482864164), np.float64(0.0032007095793208317), np.float64(0.0035494296192733975), np.float64(0.002088402270884021), np.float64(0.0019249512670565295), np.float64(0.0010336284623507445), np.float64(0.0018634896140023152), np.float64(0.0026543510459147456)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2900' max='2900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2900/2900 22:51, Epoch 24/25]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.603700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30080it [02:56, 170.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 0 invalid samples out of total 30080 samples generated. Sampling efficiency is: 100.0000%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidliu/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critic round: 25,                     sensitivity_threshold: 0.05274019980209938,                         val_sensitivity: 0.00407718005231483,                             val_sensitivities: [np.float64(0.004411764705882354), np.float64(0.005282132933087236), np.float64(0.0030817884627099014), np.float64(0.00391356323702233), np.float64(0.004601995093367937), np.float64(0.005073968993819029), np.float64(0.005075035489758671), np.float64(0.0039019687436574), np.float64(0.004532353657546481), np.float64(0.0052181633688483005), np.float64(0.0033906554185593753), np.float64(0.0030028429282160625), np.float64(0.002226767912614458), np.float64(0.0041516208869233585), np.float64(0.00329307895270956)]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3229' max='3480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3229/3480 12:37 < 09:41, 0.43 it/s, Epoch 27.81/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.597900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Initialize and fit the parent model in tabular mode.\u001b[39;00m\n\u001b[32m     20\u001b[39m parent_model = REaLTabFormer(model_type=\u001b[33m\"\u001b[39m\u001b[33mtabular\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m                              gradient_accumulation_steps=\u001b[32m8\u001b[39m,\n\u001b[32m     22\u001b[39m                              epochs=\u001b[32m50\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m                              early_stopping_patience=\u001b[32m3\u001b[39m\n\u001b[32m     27\u001b[39m                              )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mparent_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Save the parent model (this creates a folder with a unique experiment id)\u001b[39;00m\n\u001b[32m     32\u001b[39m parent_model.save(\u001b[33m\"\u001b[39m\u001b[33mrtf_ads/\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:458\u001b[39m, in \u001b[36mREaLTabFormer.fit\u001b[39m\u001b[34m(self, df, in_df, join_on, resume_from_checkpoint, device, num_bootstrap, frac, frac_max_data, qt_max, qt_max_default, qt_interval, qt_interval_unique, distance, quantile, n_critic, n_critic_stop, gen_rounds, sensitivity_max_col_nums, use_ks, full_sensitivity, sensitivity_orig_frac_multiple, orig_samples_rounds, load_from_best_mean_sensitivity, target_col)\u001b[39m\n\u001b[32m    456\u001b[39m         trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m         trainer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_with_sensitivity\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfrac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfrac_max_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrac_max_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_max\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_max_default\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_max_default\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqt_interval_unique\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqt_interval_unique\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_critic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_critic_stop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_critic_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgen_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m            \u001b[49m\u001b[43msensitivity_max_col_nums\u001b[49m\u001b[43m=\u001b[49m\u001b[43msensitivity_max_col_nums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_ks\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_ks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfull_sensitivity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_sensitivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m            \u001b[49m\u001b[43msensitivity_orig_frac_multiple\u001b[49m\u001b[43m=\u001b[49m\u001b[43msensitivity_orig_frac_multiple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m            \u001b[49m\u001b[43morig_samples_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43morig_samples_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mload_from_best_mean_sensitivity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_from_best_mean_sensitivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == ModelType.relational:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/realtabformer/realtabformer.py:710\u001b[39m, in \u001b[36mREaLTabFormer._train_with_sensitivity\u001b[39m\u001b[34m(self, df, device, num_bootstrap, frac, frac_max_data, qt_max, qt_max_default, qt_interval, qt_interval_unique, distance, quantile, n_critic, n_critic_stop, gen_rounds, sensitivity_max_col_nums, use_ks, resume_from_checkpoint, full_sensitivity, sensitivity_orig_frac_multiple, orig_samples_rounds, load_from_best_mean_sensitivity)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     trainer = \u001b[38;5;28mself\u001b[39m._build_tabular_trainer(\n\u001b[32m    706\u001b[39m         device=device,\n\u001b[32m    707\u001b[39m         num_train_epochs=num_train_epochs,\n\u001b[32m    708\u001b[39m         target_epochs=\u001b[38;5;28mself\u001b[39m.epochs,\n\u001b[32m    709\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    713\u001b[39m     \u001b[38;5;66;03m# Generate samples\u001b[39;00m\n\u001b[32m    714\u001b[39m     gen_df = \u001b[38;5;28mself\u001b[39m.sample(n_samples=gen_rounds * gen_total, device=device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:2548\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2541\u001b[39m context = (\n\u001b[32m   2542\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2545\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2546\u001b[39m )\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2548\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:3698\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3697\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3698\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3700\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3702\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3703\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3704\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/trainer.py:3759\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3757\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3758\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3759\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3760\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3761\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3762\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1089\u001b[39m, in \u001b[36mGPT2LMHeadModel.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m   1086\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1088\u001b[39m     \u001b[38;5;66;03m# Flatten the tokens\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlm_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1097\u001b[39m     output = (lm_logits,) + transformer_outputs[\u001b[32m1\u001b[39m:]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/transformers/loss/loss_utils.py:39\u001b[39m, in \u001b[36mForCausalLMLoss\u001b[39m\u001b[34m(logits, labels, vocab_size, num_items_in_batch, ignore_index, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m labels = labels.to(logits.device)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Shift so that tokens < n predict n\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m labels = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m shift_labels = labels[..., \u001b[32m1\u001b[39m:].contiguous()\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Flatten the tokens\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/realtabformer Project/newprojectenv/lib/python3.12/site-packages/torch/nn/functional.py:5209\u001b[39m, in \u001b[36mpad\u001b[39m\u001b[34m(input, pad, mode, value)\u001b[39m\n\u001b[32m   5202\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mreplicate\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   5203\u001b[39m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[32m   5204\u001b[39m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[32m   5205\u001b[39m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[32m   5206\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\n\u001b[32m   5207\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtorch._decomp.decompositions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5208\u001b[39m             )._replication_pad(\u001b[38;5;28minput\u001b[39m, pad)\n\u001b[32m-> \u001b[39m\u001b[32m5209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "from realtabformer import REaLTabFormer\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load Your Datasets\n",
        "# ---------------------------\n",
        "# Replace these file paths with your actual CSV files.\n",
        "ads_df = pd.read_csv(\"ads_df_minimal_label1.csv\")    # Contains only label 1 rows for ads\n",
        "feeds_df = pd.read_csv(\"feeds_df_minimal_label1.csv\")  # Contains only label 1 rows for feeds\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Train the Parent Model (Ads Data)\n",
        "# ---------------------------\n",
        "# Since \"user_id\" is used for joining, remove it from the features to be modeled.\n",
        "parent_features = ads_df.drop(columns=[\"user_id\"])\n",
        "\n",
        "# Initialize and fit the parent model in tabular mode.\n",
        "parent_model = REaLTabFormer(model_type=\"tabular\",\n",
        "                             gradient_accumulation_steps=8,\n",
        "                             epochs=50, \n",
        "                             batch_size = 128,\n",
        "                             logging_steps=500,\n",
        "                             early_stopping_threshold=0.01,\n",
        "                             early_stopping_patience=3\n",
        "                             )\n",
        "\n",
        "parent_model.fit(parent_features)\n",
        "\n",
        "# Save the parent model (this creates a folder with a unique experiment id)\n",
        "parent_model.save(\"rtf_ads/\")\n",
        "\n",
        "# Retrieve the path of the saved parent model (assumes the most recent is the one we need)\n",
        "parent_model_path = sorted([p for p in Path(\"rtf_ads/\").glob(\"id*\") if p.is_dir()],\n",
        "                           key=os.path.getmtime)[-1]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Train the Child Model (Feeds Data)\n",
        "# ---------------------------\n",
        "# The child (relational) model uses the feeds data.\n",
        "# It also takes the original ads data for relational joining via \"user_id.\"\n",
        "child_model = REaLTabFormer(model_type=\"relational\",\n",
        "                            parent_realtabformer_path=parent_model_path,\n",
        "                            train_size=0.8)  # You can adjust train_size as needed\n",
        "\n",
        "# Fit the child model.\n",
        "child_model.fit(\n",
        "    df=feeds_df,\n",
        "    in_df=ads_df,    # The parent table used for the join\n",
        "    join_on=\"user_id\"\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Generate Synthetic Samples\n",
        "# ---------------------------\n",
        "# Generate synthetic parent samples (for ads data)\n",
        "synthetic_ads = parent_model.sample(n_samples=len(ads_df))\n",
        "\n",
        "# Since we dropped \"user_id\" before training, you might need to reassign or generate new ids.\n",
        "# Here, we simply reset the index to create a new \"user_id\" column.\n",
        "synthetic_ads.index.name = \"user_id\"\n",
        "synthetic_ads = synthetic_ads.reset_index()\n",
        "\n",
        "# Generate synthetic child samples (for feeds data) using the relational model.\n",
        "synthetic_feeds = child_model.sample(\n",
        "    input_unique_ids=synthetic_ads[\"user_id\"],\n",
        "    input_df=synthetic_ads.drop(columns=[\"user_id\"]),\n",
        "    gen_batch=64  # Adjust batch size if needed\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Display Sample Outputs\n",
        "# ---------------------------\n",
        "print(\"Synthetic Ads Samples:\")\n",
        "print(synthetic_ads.head())\n",
        "\n",
        "print(\"\\nSynthetic Feeds Samples:\")\n",
        "print(synthetic_feeds.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'synthetic_ads' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msynthetic_ads\u001b[49m.to_csv(\u001b[33m'\u001b[39m\u001b[33msynthetic_ads.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      2\u001b[39m synthetic_feeds.to_csv(\u001b[33m'\u001b[39m\u001b[33msynthetic_feeds.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[31mNameError\u001b[39m: name 'synthetic_ads' is not defined"
          ]
        }
      ],
      "source": [
        "synthetic_ads.to_csv('synthetic_ads.csv', index=False)\n",
        "synthetic_feeds.to_csv('synthetic_feeds.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "newprojectenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24e85205297c42b0a4685e0c767da0e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4865076025c24795b4b257f16593af0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e85205297c42b0a4685e0c767da0e0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6912c9b8f315476f9591264cd534670f",
            "value": "â€‡500/500â€‡[43:06&lt;00:00,â€‡â€‡5.13s/it]"
          }
        },
        "5ad1e0ab4ca24abc9368e60dc50e0af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b22509d7b314f2c9c1ba815270583b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6912c9b8f315476f9591264cd534670f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78c253aca89a4facb5b86e9ad1699538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6001d4441884255b59485c32136cd9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85b8ef1259a4e96a1c37916772ba5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6b1fa4f4bf24bd29756c1334568ba62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_78c253aca89a4facb5b86e9ad1699538",
            "value": "Bootstrapâ€‡round:â€‡100%"
          }
        },
        "b074cd6742dd43ba8fbf1d7f11666cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a85b8ef1259a4e96a1c37916772ba5eb",
              "IPY_MODEL_ee38ea9978ff4f50b3ff9c58f9224dc4",
              "IPY_MODEL_4865076025c24795b4b257f16593af0b"
            ],
            "layout": "IPY_MODEL_a6001d4441884255b59485c32136cd9c"
          }
        },
        "c6b1fa4f4bf24bd29756c1334568ba62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee38ea9978ff4f50b3ff9c58f9224dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b22509d7b314f2c9c1ba815270583b2",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ad1e0ab4ca24abc9368e60dc50e0af9",
            "value": 500
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
